## Predicting similarity in taste of meals given their photos (final grade 5/6)

### Challenge

In this task we were given 10'000 pictures of different meals (not uploaded here for size constraints) and a training set consisting of ordered triplets. The dataset was split into two equal parts of 5000 pictures each: one was used for the training and the other one for the test. An ordered triplet might be [00002, 00034, 00018], meaning that the food in picture 00002.jpg is more similar in taste to the food in picture 00034.jpg with respect to the one in picture 00018.jpg. Given a triplet of the test set, our goal was to predict whether the first dish tastes more similar to the second one (output 0) or third one (output 1).

### Solution

We solved this problem through a more intuitive and creative strategy. We loaded the weights pre-trained on 'imagenet' (trained on various images categories, not exclusively food related) into a VGG16 neural network which we used for the training on our images. When applied to an image, the pre-trained VGG16 returns a vector with about 350 entries corresponding to the set of categories (i.e. "pizza", or "chair"). Each entry stores the probability of the image pf belonging to that specific category. Furthermore, we performed **principal component analysis** (PCA) on these 350 dimensional vectors (this helped us reduce the runtime significantly). Then we exploited **unsupervised learning** through **k-means** to cluster the dimensionally reduced vectors. In order to make predictions, we built a grid with elements associated to pairs of classes, i.e. k-means clusters. In particular, consider we have again the training triplet [00002, 00034, 00018] and suppose that pictures are mapped to clusters ith, jth and kth ([00002, 00034, 00018] --> [i-th, j-th, k-th]). We then sum 1 to entries (i,j) and (j,i) in the grid, whereas we subtract 1 (i,k) and (k,i). 

For making predictions, we apply the same preprocessing (i.e. VGG16 regression and PCA) to test images, we then look at the clusters they belong to (previously computed thorugh k-means), and use the grids' values to measure taste similarity. Finally, we vary both the value of PCA components and the number of clusters of k-means and we use cross validation to test their goodness. As the performance varied just slightly while predictions were quite different (for different values of PCA components and K-means clusters) we made many predictions and picked the final one in a majority vote fashion. This method increased the score obtained through cross validation by nearly 10%, **with a final confidence of 65%**.
